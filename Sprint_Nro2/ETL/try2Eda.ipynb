{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from google.cloud import storage\n",
    "import hashlib\n",
    "\n",
    "def generate_md5(value):\n",
    "    return hashlib.md5(value.encode()).hexdigest()\n",
    "\n",
    "def download_from_gcs(bucket_name, files, destination_folder):\n",
    "    client = storage.Client()\n",
    "    bucket = client.bucket(bucket_name)\n",
    "    os.makedirs(destination_folder, exist_ok=True)\n",
    "    \n",
    "    for file in files:\n",
    "        blob = bucket.blob(file)\n",
    "        destination_path = os.path.join(destination_folder, os.path.basename(file))\n",
    "        blob.download_to_filename(destination_path)\n",
    "        print(f\"üì• Descargado: {file}\")\n",
    "\n",
    "def load_dataframes(destination_folder):\n",
    "    dataframes = {}\n",
    "    for file in os.listdir(destination_folder):\n",
    "        if file.endswith('.csv'):\n",
    "            df_name = file.replace('.csv', '_cleaned')\n",
    "            dataframes[df_name] = pd.read_csv(os.path.join(destination_folder, file))\n",
    "    return dataframes\n",
    "\n",
    "def convert_types(dataframes):\n",
    "    for name, df in dataframes.items():\n",
    "        for col in df.select_dtypes(include=['object']).columns:\n",
    "            df[col] = df[col].astype(str)\n",
    "    return dataframes\n",
    "\n",
    "def transform_data(dataframes):\n",
    "    users_cleaned = dataframes['users_cleaned'][['user_id', 'name', 'review_count', 'yelping_since']]\n",
    "    users_cleaned['yelping_since'] = pd.to_datetime(users_cleaned['yelping_since']).dt.date\n",
    "    \n",
    "    reviews_cleaned = dataframes['reviews_cleaned'][['review_id', 'business_id', 'user_id', 'stars', 'text', 'date']]\n",
    "    reviews_cleaned.rename(columns={'date': 'review_date'}, inplace=True)\n",
    "    reviews_cleaned['review_date'] = pd.to_datetime(reviews_cleaned['review_date']).dt.date\n",
    "    reviews_cleaned['stars'] = reviews_cleaned['stars'].astype(int)\n",
    "    \n",
    "    business_cleaned = dataframes['business_cleaned'][['business_id', 'name', 'address', 'city', 'categories', 'latitude', 'longitude', 'review_count']]\n",
    "    business_cleaned.rename(columns={'name': 'business_name'}, inplace=True)\n",
    "    \n",
    "    cities = business_cleaned[['city']].drop_duplicates().copy()\n",
    "    cities['city_id'] = cities['city'].apply(generate_md5)\n",
    "    business_cleaned = business_cleaned.merge(cities, on='city', how='left').drop(columns=['city'])\n",
    "    cities = cities[['city_id', 'city']]\n",
    "    \n",
    "    categories = business_cleaned[['categories']].drop_duplicates().copy()\n",
    "    categories['category_id'] = categories['categories'].apply(generate_md5)\n",
    "    business_cleaned = business_cleaned.merge(categories, on='categories', how='left')\n",
    "    categories = categories[['category_id', 'categories']]\n",
    "    categories.rename(columns={'categories': 'category'}, inplace=True)\n",
    "    \n",
    "    return {\n",
    "        'users_cleaned': users_cleaned,\n",
    "        'reviews_cleaned': reviews_cleaned,\n",
    "        'business_cleaned': business_cleaned,\n",
    "        'cities': cities,\n",
    "        'categories': categories\n",
    "    }\n",
    "\n",
    "def plot_and_export(dataframes, output_path, bucket):\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    dataframes = {k: v for k, v in dataframes.items() if v is not None}\n",
    "    \n",
    "    for name, df in dataframes.items():\n",
    "        if not df.empty:\n",
    "            numeric_df = df.select_dtypes(include=[np.number])\n",
    "            for col in numeric_df.columns:\n",
    "                plt.figure(figsize=(10, 5))\n",
    "                sns.histplot(numeric_df[col], bins=30, kde=True)\n",
    "                plt.axvline(numeric_df[col].mean(), color='r', linestyle='dashed', linewidth=2, label='Media')\n",
    "                plt.title(f'Distribuci\\u00f3n de {col} en {name}')\n",
    "                plt.legend()\n",
    "                plt.show()\n",
    "            \n",
    "            csv_path = os.path.join(output_path, f\"{name}.csv\")\n",
    "            df.to_csv(csv_path, index=False)\n",
    "            \n",
    "            blob = bucket.blob(f\"ETL/{name}.csv\")\n",
    "            blob.upload_from_filename(csv_path)\n",
    "            print(f\"‚òÅÔ∏è Archivo subido a GCS: ETL/{name}.csv\")\n",
    "\n",
    "def main():\n",
    "    bucket_name = \"tu_bucket\"\n",
    "    files = [\"users.csv\", \"reviews.csv\", \"business.csv\"]\n",
    "    destination_folder = \"data\"\n",
    "    output_path = \"output\"\n",
    "    \n",
    "    download_from_gcs(bucket_name, files, destination_folder)\n",
    "    dataframes = load_dataframes(destination_folder)\n",
    "    dataframes = convert_types(dataframes)\n",
    "    transformed_data = transform_data(dataframes)\n",
    "    \n",
    "    client = storage.Client()\n",
    "    bucket = client.bucket(bucket_name)\n",
    "    plot_and_export(transformed_data, output_path, bucket)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "end",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
