{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from google.cloud import storage\n",
    "\n",
    "def download_from_gcs(bucket_name, files, destination_folder):\n",
    "    os.makedirs(destination_folder, exist_ok=True)\n",
    "    client = storage.Client()\n",
    "    bucket = client.bucket(bucket_name)\n",
    "    \n",
    "    for file in files:\n",
    "        blob = bucket.blob(file)\n",
    "        file_path = os.path.join(destination_folder, os.path.basename(file))\n",
    "        blob.download_to_filename(file_path)\n",
    "        print(f\"‚úÖ Descargado: {file} ‚Üí {file_path}\")\n",
    "\n",
    "def load_dataframes(destination_folder):\n",
    "    dataframes = {}\n",
    "    \n",
    "    for file in os.listdir(destination_folder):\n",
    "        file_path = os.path.join(destination_folder, file)\n",
    "        \n",
    "        if file.endswith(\".parquet\"):\n",
    "            try:\n",
    "                print(f\"üìÇ Convirtiendo Parquet a CSV: {file}\")\n",
    "                df = pd.read_parquet(file_path)\n",
    "                csv_file = file.replace(\".parquet\", \".csv\")\n",
    "                csv_path = os.path.join(destination_folder, csv_file)\n",
    "                df.to_csv(csv_path, index=False)\n",
    "                print(f\"‚úÖ Archivo convertido: {csv_file}\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Error al convertir {file}: {e}\")\n",
    "        \n",
    "        elif file.endswith(\".csv\"):\n",
    "            try:\n",
    "                print(f\"üìÇ Cargando: {file}\")  \n",
    "                df = pd.read_csv(file_path)\n",
    "                dataframes[file.replace(\".csv\", \"\")] = df\n",
    "            except pd.errors.EmptyDataError:\n",
    "                print(f\"‚ö†Ô∏è Archivo vac√≠o o sin columnas: {file}\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Error al cargar {file}: {e}\")\n",
    "\n",
    "    print(\"‚úÖ Archivos cargados en DataFrames.\")\n",
    "    return dataframes\n",
    "\n",
    "\n",
    "def convert_types(dataframes):\n",
    "    for name, df in dataframes.items():\n",
    "        for col in df.columns:\n",
    "            if df[col].dtype == \"object\":\n",
    "                try:\n",
    "                    df[col] = pd.to_datetime(df[col], format=\"%Y-%m-%d\", errors=\"coerce\")\n",
    "                except:\n",
    "                    pass\n",
    "            if df[col].dtype == \"object\" and df[col].nunique() < len(df) * 0.5:\n",
    "                df[col] = df[col].astype(\"category\")\n",
    "    print(\"‚úÖ Tipos de datos convertidos correctamente.\")\n",
    "\n",
    "def process_missing_values(dataframes):\n",
    "    for name, df in dataframes.items():\n",
    "        for col in df.select_dtypes(include=[np.number]).columns:\n",
    "            df[col] = df[col].fillna(df[col].mean())\n",
    "    print(\"‚úÖ Valores nulos tratados correctamente.\")\n",
    "\n",
    "def transform_for_dw(dataframes):\n",
    "    transformed = {\n",
    "        \"dim_category\": dataframes[\"business_cleaned\"][[\"category_id\", \"category\"]].drop_duplicates(),\n",
    "        \"dim_city\": dataframes[\"business_cleaned\"][[\"city_id\", \"city\"]].drop_duplicates(),\n",
    "        \"dim_business\": dataframes[\"business_cleaned\"][[\"business_id\", \"business_name\", \"address\", \"city_id\", \"category_id\", \"latitude\", \"longitude\", \"review_count\"]],\n",
    "        \"fact_reviews\": dataframes[\"review_cleaned\"][[\"review_id\", \"business_id\", \"user_id\", \"category_id\", \"review_date\", \"stars\", \"text\"]],\n",
    "        \"dim_user\": dataframes[\"users_cleaned\"][[\"user_id\", \"name\", \"review_count\", \"yelping_since\"]],\n",
    "        \"fact_checkin\": dataframes[\"checkins_expanded\"][[\"checkin_id\", \"business_id\", \"checkin_date\", \"checkin_count\"]]\n",
    "    }\n",
    "    print(\"‚úÖ DataFrames transformados para proyecto_dw.\")\n",
    "    return transformed\n",
    "\n",
    "def plot_and_export(dataframes, output_path, bucket):\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    for name, df in dataframes.items():\n",
    "        if not df.empty:\n",
    "            numeric_df = df.select_dtypes(include=[np.number])\n",
    "            for col in numeric_df.columns:\n",
    "                plt.figure(figsize=(10, 5))\n",
    "                sns.histplot(numeric_df[col], bins=30, kde=True)\n",
    "                plt.axvline(numeric_df[col].mean(), color='r', linestyle='dashed', linewidth=2, label='Media')\n",
    "                plt.title(f'Distribuci√≥n de {col} en {name}')\n",
    "                plt.legend()\n",
    "                plt.show()\n",
    "            \n",
    "            csv_path = os.path.join(output_path, f\"{name}.csv\")\n",
    "            df.to_csv(csv_path, index=False)\n",
    "            \n",
    "            blob = bucket.blob(f\"ETL/{name}.csv\")\n",
    "            blob.upload_from_filename(csv_path)\n",
    "            print(f\"‚òÅÔ∏è Archivo subido a GCS: ETL/{name}.csv\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\Documents\\Henry\\PF\\end\\Lib\\site-packages\\google_crc32c\\__init__.py:29: RuntimeWarning: As the c extension couldn't be imported, `google-crc32c` is using a pure python implementation that is significantly slower. If possible, please configure a c build environment and compile the extension\n",
      "  warnings.warn(_SLOW_CRC32C_WARNING, RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Descargado: Yelp/processed/user_cleaned.csv ‚Üí ./dataWorkingon\\user_cleaned.csv\n",
      "‚úÖ Descargado: Yelp/processed/reviews_cleaned.csv ‚Üí ./dataWorkingon\\reviews_cleaned.csv\n",
      "‚úÖ Descargado: Yelp/processed/users_cleaned.csv ‚Üí ./dataWorkingon\\users_cleaned.csv\n",
      "‚úÖ Descargado: Yelp/processed/tips_cleaned.csv ‚Üí ./dataWorkingon\\tips_cleaned.csv\n",
      "‚úÖ Descargado: Yelp/processed/review_cleaned.csv ‚Üí ./dataWorkingon\\review_cleaned.csv\n",
      "‚úÖ Descargado: Yelp/processed/business_cleaned.csv ‚Üí ./dataWorkingon\\business_cleaned.csv\n",
      "‚úÖ Descargado: Yelp/processed/business_cleaned.parquet ‚Üí ./dataWorkingon\\business_cleaned.parquet\n"
     ]
    }
   ],
   "source": [
    "# Configurar la autenticaci√≥n con la clave de servicio JSON\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"proyectofinalgogleyelp-41e96ec7a40a.json\"\n",
    "\n",
    "# Configuraci√≥n\n",
    "bucket_name = \"dataset-pf-gyelp\"\n",
    "destination_folder = \"./dataWorkingon\"\n",
    "output_path = \"./output_data\"\n",
    "\n",
    "files = [\n",
    "    \"Yelp/processed/user_cleaned.csv\",\n",
    "    \"Yelp/processed/reviews_cleaned.csv\",\n",
    "    \"Yelp/processed/users_cleaned.csv\",\n",
    "    \"Yelp/processed/tips_cleaned.csv\",\n",
    "    \"Yelp/processed/review_cleaned.csv\",\n",
    "    \"Yelp/processed/business_cleaned.csv\",\n",
    "    \"Yelp/processed/business_cleaned.parquet\"\n",
    "]\n",
    "\n",
    "# Inicializar cliente de almacenamiento\n",
    "client = storage.Client()\n",
    "bucket = client.bucket(bucket_name)\n",
    "\n",
    "# Proceso ETL\n",
    "download_from_gcs(bucket_name, files, destination_folder)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_27856\\3285177241.py:4: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  return pd.read_csv(file_path)\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_27856\\3285177241.py:4: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  return pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Error: Archivo no encontrado -> dataWorkingon\\business_cleaned\n",
      "‚úîÔ∏è reviews_cleaned.csv cargado con 6990282 filas\n",
      "‚úîÔ∏è users_cleaned.csv cargado con 2105597 filas\n",
      "‚úîÔ∏è tips_cleaned.csv cargado con 908915 filas\n",
      "‚úîÔ∏è review_cleaned.csv cargado con 4559049 filas\n",
      "‚úîÔ∏è user_cleaned.csv cargado con 1987897 filas\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ Definir la funci√≥n primero\n",
    "def load_csv(file_path):\n",
    "    if os.path.exists(file_path):  # Verifica si el archivo existe\n",
    "        return pd.read_csv(file_path)\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Error: Archivo no encontrado -> {file_path}\")\n",
    "        return None  # Retorna None si el archivo no existe\n",
    "\n",
    "# ‚úÖ Luego, usarla para leer archivos\n",
    "base_path = \"dataWorkingon\"\n",
    "\n",
    "files = [\"reviews_cleaned.csv\",  \"users_cleaned.csv\",\n",
    "         \"tips_cleaned.csv\", \"tips_cleaned.csv\", \"review_cleaned.csv\",  \"user_cleaned.csv\", \"business_cleaned.parquet\"]\n",
    "\n",
    "# ‚úÖ Asegurarse de que load_csv est√© definida antes de usarla\n",
    "dataframes = {file: load_csv(os.path.join(base_path, file)) for file in files}\n",
    "\n",
    "# ‚úÖ Revisar qu√© archivos se cargaron correctamente\n",
    "for file, df in dataframes.items():\n",
    "    if df is not None:\n",
    "        print(f\"‚úîÔ∏è {file} cargado con {len(df)} filas\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Cargando: business_cleaned.csv\n",
      "üìÇ Convirtiendo Parquet a CSV: business_cleaned.parquet\n",
      "‚úÖ Archivo convertido: business_cleaned.csv\n",
      "üìÇ Cargando: reviews_cleaned.csv\n",
      "üìÇ Cargando: review_cleaned.csv\n",
      "üìÇ Cargando: tips_cleaned.csv\n",
      "üìÇ Cargando: users_cleaned.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_27856\\1097575762.py:39: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Cargando: user_cleaned.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_27856\\1097575762.py:39: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    }
   ],
   "source": [
    "dataframes = load_dataframes(destination_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Tipos de datos convertidos correctamente.\n"
     ]
    }
   ],
   "source": [
    "convert_types(dataframes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Valores nulos tratados correctamente.\n"
     ]
    }
   ],
   "source": [
    "process_missing_values(dataframes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['category_id', 'category'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m transformed_dataframes \u001b[38;5;241m=\u001b[39m \u001b[43mtransform_for_dw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataframes\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[2], line 70\u001b[0m, in \u001b[0;36mtransform_for_dw\u001b[1;34m(dataframes)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtransform_for_dw\u001b[39m(dataframes):\n\u001b[0;32m     69\u001b[0m     transformed \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m---> 70\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdim_category\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mdataframes\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbusiness_cleaned\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcategory_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcategory\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mdrop_duplicates(),\n\u001b[0;32m     71\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdim_city\u001b[39m\u001b[38;5;124m\"\u001b[39m: dataframes[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbusiness_cleaned\u001b[39m\u001b[38;5;124m\"\u001b[39m][[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcity_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcity\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\u001b[38;5;241m.\u001b[39mdrop_duplicates(),\n\u001b[0;32m     72\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdim_business\u001b[39m\u001b[38;5;124m\"\u001b[39m: dataframes[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbusiness_cleaned\u001b[39m\u001b[38;5;124m\"\u001b[39m][[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbusiness_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbusiness_name\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maddress\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcity_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategory_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlatitude\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlongitude\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreview_count\u001b[39m\u001b[38;5;124m\"\u001b[39m]],\n\u001b[0;32m     73\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfact_reviews\u001b[39m\u001b[38;5;124m\"\u001b[39m: dataframes[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreview_cleaned\u001b[39m\u001b[38;5;124m\"\u001b[39m][[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreview_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbusiness_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategory_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreview_date\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstars\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m]],\n\u001b[0;32m     74\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdim_user\u001b[39m\u001b[38;5;124m\"\u001b[39m: dataframes[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musers_cleaned\u001b[39m\u001b[38;5;124m\"\u001b[39m][[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreview_count\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myelping_since\u001b[39m\u001b[38;5;124m\"\u001b[39m]],\n\u001b[0;32m     75\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfact_checkin\u001b[39m\u001b[38;5;124m\"\u001b[39m: dataframes[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheckins_expanded\u001b[39m\u001b[38;5;124m\"\u001b[39m][[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheckin_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbusiness_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheckin_date\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheckin_count\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[0;32m     76\u001b[0m     }\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚úÖ DataFrames transformados para proyecto_dw.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m transformed\n",
      "File \u001b[1;32mc:\\Users\\PC\\Documents\\Henry\\PF\\end\\Lib\\site-packages\\pandas\\core\\frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\PC\\Documents\\Henry\\PF\\end\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\PC\\Documents\\Henry\\PF\\end\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6249\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[0;32m   6248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nmissing \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[1;32m-> 6249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m     not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m   6252\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['category_id', 'category'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "transformed_dataframes = transform_for_dw(dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportar\n",
    "client = storage.Client()\n",
    "bucket = client.bucket(bucket_name)\n",
    "plot_and_export(transformed_dataframes, output_path, bucket)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "end",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
